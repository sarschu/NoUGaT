% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{NoUGaT Documentation}
\date{February 05, 2015}
\release{1}
\author{Sarah Schulz, Bart Desmet, Orphee DeClercq}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


Contents:


\chapter{Tutorial}
\label{README:welcome-to-nougat-s-documentation}\label{README::doc}\label{README:tutorial}
Contributors: Sarah Schulz, Bart Desmet, Orphee De Clercq, Arda Tezcan, Guy De Pauw

Version 1.0

Date 15th November 2014

contact: \href{mailto:Sarah.Schulz@Ugent.be}{Sarah.Schulz@Ugent.be}

The Normalizer converts User Generated Contents into a normalized version that can be further processed with NLP tools.
It has been trained on three different genres of UGC namely Twitter data, SMS and Netlog. It works for Dutch as well as for English.


\section{System architecture}
\label{README:system-architecture}
The normalization pipeline consists of different more or less independent modules.
\begin{itemize}
\item {} 
the preprocessing module

\item {} 
the suggestion-generation modules

\item {} 
the decision module

\end{itemize}


\subsection{Preprocessing}
\label{README:preprocessing}
The first step that is performed is the preprocessing of the input files.

The program works on the sentence level. That means that the input is split into sentences first.

The following replacements of  characters talk place:
* smilies
* tags
* hyperlink


\subsection{Suggestion generation}
\label{README:suggestion-generation}
There are 8 different modules that generate possible normalization option for each word in a sentence. Some modules
generate exactly one output for each word, others do not deliver an option for every word but can deliver more than one
possible option per word.

The modules cover different levels of mistakes that can appear in UGC such as spelling errors or phonetic expressions.


\subsubsection{Abbreviation}
\label{README:abbreviation}
Language used in UGC often shares certain abbreviations and uniform ways of reference like hash tags in Twitter posts. Therefore, lookup approaches can cover a reasonable number of issues.

The abbreviation module relies on a dictionary of about 350 frequent abbreviations appearing in social media texts like \emph{lol} (laughing out loud) and \emph{aub} for (alstublieft) (thank you).


\subsubsection{Compound}
\label{README:compound}
It is often the case (and certainly more often for Dutch than for English) that compounds that should actually be written in one
word are written in two words.

To account for this compounding mistakes the compound module tests for all two words that are written next to each other if a
spell checker (hunspell) recognizes them as correctly spelled word when they are written as one word. If that is the case, the
compound version is returned as a possible option for the two words.

The output of this module is a phrase (the two original words) along with a one word option. This is possible since we later one work
with phrase-based machine translation. If there is no compound correction in the input sentence the output is an empty list.


\subsubsection{Empty}
\label{README:empty}
A module which is not included by default. It returns the empty string for each token in order to give the possibility to delete tokens.


\subsubsection{Named entity module}
\label{README:named-entity-module}
This is a module that differs from the other modules. It does not give options but returns information that can be used later as a feature. By default, this module is not included.

Named entities (NEs) should not be normalized and it is therefore important to recognize them as such in order to avoid overcorrection. Since NEs in UGC have different characteristics than in standard texts (NEs frequently lack capitalization or are introduced with specific characters as @ or \#), we developed a dedicated named entity recognition (NER) tool.

The NER tool is hybrid in the sense that it uses gazetteer lookup and classification. The gazetteers  contain a variety of named entities. Moreover, it includes a simple pattern-matching rule to find words with a capitalized first letter which does not appear at the beginning of a sentence.
\begin{quote}

Other than abbreviations, NEs are a highly productive group, so a lookup approach does not suffice.
\end{quote}

For that reason, we added a conditional random field classifier trained on the training set of our corpus. It reaches a high performance (F-score of 0.9) and has been trained with features tailored to named entities in UGC.


\subsubsection{Original}
\label{README:original}
The original module returns the original word as an option for the word. This is important since some of the words are not
erroneous and could get lost when no other module returns the original option.

The output of this module is the original word along with exactly one option (which is the same word as the input word).


\subsubsection{G2P2G}
\label{README:g2p2g}
UGC often contains mistakes that are due to the ``spell like you pronounce it'' style. Often words are a graphematic representation of
how a word is pronounced. To be able to translate those words to the correct spelling we first have to find a phonetic representation
that is close to the graphematic representation and then use a lookup dictionary to find the correct orthographic representation of the
similar phonetic string.

The module performs the following steps:
\begin{enumerate}
\item {} 
The graphematic original word is with the help of a memory-based translation system translated into its phonetic representation

\item {} 
certain replacement strategies borrowed from spell checking approaches are used in order to generate similar phonetic strings (namely splits, deletes, transposes, replaces, inserts and of course also the phonetic representation of the original string)

\item {} 
all the phonetic alternatives are looked up in a dictionary containing phonetic strings along with its grapheme translations.

\item {} 
all grapheme translations that can be found for the phonetic alternatives are returned as possible options of the original word

\end{enumerate}

(implemented by Guy De Pauw)


\subsubsection{SMT}
\label{README:smt}
Following preliminary experiments described in DeClercq (2013), the SMT models have been trained on token and character level using Moses. The language model used has been built from a combination of four corpora using KenLM.

There are four different modules that work with statistical machine translation.
\begin{itemize}
\item {} 
unigram module

\item {} 
bigram module

\item {} 
token module

\item {} 
cascaded module

\end{itemize}

All those modules work with Moses models. Since the program works on the sentence level we included Moses sever mode in order
to avoid loading the model files of Moses for each sentence.


\subsubsection{Spell checker}
\label{README:spell-checker}
The spell checker module uses hunspell (and its python wrapper pyhunspell). Each word in the original sentence is spell checked.
In case hunspell classifies a word as wrongly-spelled, the correction suggestions given by hunspell are returned as alternatives.
The output of the spell checker module is a list of spell checker suggestions for each wrongly-spelled word.


\subsubsection{Word split}
\label{README:word-split}
Theword split module is the opposite of the compound module and splits words that have been erroneously written together. In UGC words are often concatenated in order to save space.

The word split module is based on the compound-splitter module of Moses  and has been trained on the Corpus Gesproken Netherlands (CGN).
It often appears that words that are actually two words are written together.


\subsection{Decision module}
\label{README:decision-module}
Since we have no a-priori knowledge about the nature of a normalization problem, each sentence is sent to all modules of the suggestion  layer. In order to prevent an avalanche of suggestions, for each module of the suggestion layer, we restricted the number of suggestions per token to one.

It is the task of the decision module to choose the most probable combination of suggestions  to build a well-formed sentence, which poses a combinatorial problem. The decision module itself makes use of the Moses decoder, a powerful, highly efficient tool able to solve the combinatorial problem with the aid of a language model of standard languagein order to include probability information.

We include the normalization suggestions in form of a phrase table into the decoding process. The decoder weights have been manually tuned using development data. However, the weights might not be ideal for decoding the dynamically compiled phrase tables containing the normalization suggestions. We include weights for the different components of the decoding process like the language model. the translation model, word penalty and distortion. Distortion is made expensive since we want to avoid reordering. Moreover, the decoder uses features containing information about which module returned which suggestion. The feature weights are first set to 0.2 and later tuned on the development data


\section{Example of usage}
\label{README:example-of-usage}
The system requires 3 arguments and is run like this:

run\_norm.py \textless{}lang\textgreater{} \textless{}inputfile\textgreater{} \textless{}outputfile\textgreater{}

The two last arguments serve evaluation and can be ignored
Run it from the norm directory. The log files will be located in the log directory after the run.
In case you have questions, ask me.
\begin{itemize}
\item {} 
\textless{}lang\textgreater{}:       can take value ``nl'' and ``en''

\item {} 
\textless{}inputfile\textgreater{}:  inputfile is a text file containing one messages per line. Those will be handeled as one to not lose context

\item {} 
\textless{}outputfile\textgreater{}: the file to which the normalized messages will be written.

\end{itemize}

The system can also just be run in preprocessing mode:

run\_prepro.py \textless{}lang\textgreater{} \textless{}inputfile\textgreater{} \textless{}outputfile\textgreater{}


\chapter{System Requirements}
\label{README:system-requirements}
The system has been tested on a 64-bit Ubuntu machine.
The following tools and packages have to be installed and the paths have to be adjusted in order to run the normalizer.
\begin{itemize}
\item {} 
Moses (compiled with server mode and SRILM setting)

\item {} 
xmlrpc-c 1.25.23 (Moses has to be compiled with the --with-xmlrpc-c in order to include it)

\item {} 
hunspell

\item {} 
pyhunspell 0.1

\item {} 
pytest

\item {} 
scikit-learn

\item {} 
nltk

\end{itemize}


\chapter{API}
\label{API:api}\label{API::doc}

\section{Preprocessing}
\label{API:module-norm.data}\label{API:preprocessing}\index{norm.data (module)}\index{Text (class in norm.data)}

\begin{fulllineitems}
\phantomsection\label{API:norm.data.Text}\pysiglinewithargsret{\strong{class }\code{norm.data.}\bfcode{Text}}{\emph{text}, \emph{n}, \emph{r}}{}
Represents a text, such as an SMS, a blogpost or a tweet
\index{\_preprocess() (norm.data.Text method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.data.Text._preprocess}\pysiglinewithargsret{\bfcode{\_preprocess}}{}{}
preprocess input text (tokenization, special character replacement)

\end{fulllineitems}

\index{\_validate\_input() (norm.data.Text method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.data.Text._validate_input}\pysiglinewithargsret{\bfcode{\_validate\_input}}{\emph{t}}{}
validate that input string is unicode
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
an input message

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
input is a unicode string or not

\item[{rtype}] \leavevmode
boolean

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.prepro.rewrite}\index{norm.prepro.rewrite (module)}\index{Rewrite (class in norm.prepro.rewrite)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite}\pysiglinewithargsret{\strong{class }\code{norm.prepro.rewrite.}\bfcode{Rewrite}}{\emph{normalizer}}{}
This class preprocesses the text including tokenization, special character replacement, 
deletion of more than one whitespace.

INPUT: line (@janthans @SvenOrnelis BBQ? Wie, wat , waar? :-D \#aanwezig)

OUTPUT: tokenized sentence with replacements (@janthans @SvenOrnelis BBQ? Wie, wat , waar? • aanwezig)

Placeholders list sign ``•''
\index{correct\_at\_tok() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.correct_at_tok}\pysiglinewithargsret{\bfcode{correct\_at\_tok}}{\emph{t}}{}
correct missed tokenization with @
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with whitespace deleted after @

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{reduce\_allcaps() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.reduce_allcaps}\pysiglinewithargsret{\bfcode{reduce\_allcaps}}{\emph{t}}{}
lowercase sequences of more than 1 uppercased letter
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with replacement characters for smileys

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{replace\_hashtags() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.replace_hashtags}\pysiglinewithargsret{\bfcode{replace\_hashtags}}{\emph{t}}{}
replace \#tags like \#workisboring with a special character
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with replacement characters for hash tags

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{replace\_hyperlinks() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.replace_hyperlinks}\pysiglinewithargsret{\bfcode{replace\_hyperlinks}}{\emph{t}}{}
replace hyperlink with replacement character
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with replacement characters for hyperlinks

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{replace\_linebreaks() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.replace_linebreaks}\pysiglinewithargsret{\bfcode{replace\_linebreaks}}{\emph{t}}{}
delete the string \textless{}LINEBREAK\textgreater{}
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string without \textless{}LINEBREAK\textgreater{}

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{replace\_pipe() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.replace_pipe}\pysiglinewithargsret{\bfcode{replace\_pipe}}{\emph{t}}{}
replace \textbar{} wirht '' ``
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with replacement of \textbar{}

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{replace\_smileys() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.replace_smileys}\pysiglinewithargsret{\bfcode{replace\_smileys}}{\emph{t}}{}
replace all smiley characters with a special character
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with replacement characters for smileys

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{replace\_spaces() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.replace_spaces}\pysiglinewithargsret{\bfcode{replace\_spaces}}{\emph{t}}{}
replace all spaces with just one space
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with max one whitespace in a row

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{replace\_tags() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.replace_tags}\pysiglinewithargsret{\bfcode{replace\_tags}}{\emph{t}}{}
replace {[}*{]} with replacement character
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string with replacement characters for tags

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{rewrite\_text() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.rewrite_text}\pysiglinewithargsret{\bfcode{rewrite\_text}}{\emph{t}, \emph{norm}}{}
call all the replacement and preprocesing methods on the input
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{param norm}] \leavevmode
a normalizer for language information

\item[{type norm}] \leavevmode
Normalizer object

\item[{return}] \leavevmode
the preprocessed string

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{tokenize() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{t}, \emph{norm}}{}
tokenize the text with a special pretokenizer and a perl script from TreeTagger
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{param norm}] \leavevmode
a normalizer for language information

\item[{type norm}] \leavevmode
Normalizer object

\item[{return}] \leavevmode
the tokenized string

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{tokenize\_placeholders() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.tokenize_placeholders}\pysiglinewithargsret{\bfcode{tokenize\_placeholders}}{\emph{t}}{}
correct the tokenization of the special characters
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
string with special characters being tokenized

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{tolower() (norm.prepro.rewrite.Rewrite method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.prepro.rewrite.Rewrite.tolower}\pysiglinewithargsret{\bfcode{tolower}}{\emph{t}}{}
lowercase string
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
input text

\item[{type t}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the string in lowercase

\item[{rtype}] \leavevmode
Unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.flooding}\index{norm.modules.flooding (module)}\index{Flooding (class in norm.modules.flooding)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.flooding.Flooding}\pysiglinewithargsret{\strong{class }\code{norm.modules.flooding.}\bfcode{Flooding}}{\emph{normalizer}}{}
this class corrects the flooding of characters and punctionation,
it reduces flooding to one and two characters and checks whether a correct word emerges
with the help of spell checking. In case it does it returns the whole sentence
It also corrects punctuation flooding. It does that in any case.
\index{check\_for\_correctness() (norm.modules.flooding.Flooding method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.flooding.Flooding.check_for_correctness}\pysiglinewithargsret{\bfcode{check\_for\_correctness}}{\emph{token}}{}
Check if token is marked as correct by hunspell or is found in the abbreviation dictionary.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
original token

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
word is correct word or not

\item[{rtype}] \leavevmode
boolean

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{correct\_flooding\_to\_one() (norm.modules.flooding.Flooding method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.flooding.Flooding.correct_flooding_to_one}\pysiglinewithargsret{\bfcode{correct\_flooding\_to\_one}}{\emph{t}}{}
Correct flooding characters using regex matches to one repetitions.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
original token

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
tuple: first part gives information if the suggested token is marked as correct by hunspell, corrected token

\item[{rtype}] \leavevmode
tuple(boolean, string)

\end{description}\end{quote}

\end{description}

Reduce all character flooding to one subsequent characters.

\end{fulllineitems}

\index{correct\_flooding\_to\_two() (norm.modules.flooding.Flooding method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.flooding.Flooding.correct_flooding_to_two}\pysiglinewithargsret{\bfcode{correct\_flooding\_to\_two}}{\emph{t}}{}
Correct flooding characters using regex matches to two repetitions.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
original token

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
tuple: first part gives information if the suggested token is marked as correct by hunspell, corrected token

\item[{rtype}] \leavevmode
tuple(boolean, string)

\end{description}\end{quote}

\end{description}

Reduce all character flooding to two subsequent characters. For Dutch the e is 
corrected to 3 repetitions first to check if an existing word emerges.

\end{fulllineitems}

\index{correct\_punctuation\_flooding() (norm.modules.flooding.Flooding method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.flooding.Flooding.correct_punctuation_flooding}\pysiglinewithargsret{\bfcode{correct\_punctuation\_flooding}}{\emph{t}}{}
Correct flooding punctuations using regex matches.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
original token

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
punctuation flooding corrected token

\item[{rtype}] \leavevmode
unicode string

\end{description}\end{quote}

\end{description}

Reduce all punctuation flooding to two subsequent characters, just dots are 
corrected to three.

\end{fulllineitems}

\index{flooding\_correct() (norm.modules.flooding.Flooding method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.flooding.Flooding.flooding_correct}\pysiglinewithargsret{\bfcode{flooding\_correct}}{\emph{t}}{}
Correct flooding characters and character combinations in t.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
original message

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
flooding corrected original message

\item[{rtype}] \leavevmode
unicode string

\end{description}\end{quote}

\end{description}

Two versions of the corrected string are compiled: correction to one or two repetitions. In case
the correction to one character produces a valid word, take this one, otherwise correct to two characters.

The sentence is corrected word by word and joined in the end.

\end{fulllineitems}

\index{hunspell\_check() (norm.modules.flooding.Flooding method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.flooding.Flooding.hunspell_check}\pysiglinewithargsret{\bfcode{hunspell\_check}}{\emph{word}}{}
check word for spelling
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param word}] \leavevmode
a word

\item[{type word}] \leavevmode
unicode string

\item[{return}] \leavevmode
return True or False dependent on word being in dict or not

\item[{rtype}] \leavevmode
boolean

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\section{Main}
\label{API:main}\label{API:module-norm.normalizer}\index{norm.normalizer (module)}\index{Normalizer (class in norm.normalizer)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer}\pysiglinewithargsret{\strong{class }\code{norm.normalizer.}\bfcode{Normalizer}}{\emph{language='nl'}, \emph{**kwargs}}{}
Pipeline for text normalization

Programm flow:
it gets the preprocessed text
it flooding corrects
its sends this corrected version to the
different modules
it takes the output per sentence and writes to phrase table
it starts the moses decoder with this phrase table
it returns the normalized sentence
\index{\_call\_moses() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer._call_moses}\pysiglinewithargsret{\bfcode{\_call\_moses}}{\emph{s}, \emph{phrase\_table}}{}
decide for a combination of suggestions
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param s}] \leavevmode
is the original message that has also been forwarded to the modules

\item[{type s}] \leavevmode
unicode string

\item[{param phrase\_table}] \leavevmode
is the path to the phrase table

\item[{type phrase\_table}] \leavevmode
string

\item[{return}] \leavevmode
return normalized sentences

\item[{rtype}] \leavevmode
string

\end{description}\end{quote}

\end{description}

Moses is called including the phrase table that has been generated from the suggestions.
Using a language model and the phrase table with its features, Moses translates the             original sentence into the normalized sentence.

\end{fulllineitems}

\index{\_check\_hunspell() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer._check_hunspell}\pysiglinewithargsret{\bfcode{\_check\_hunspell}}{\emph{word}}{}
check word for spelling
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param word}] \leavevmode
a word

\item[{type word}] \leavevmode
unicode string

\item[{return}] \leavevmode
return True or False dependent on word being in dict or not

\item[{rtype}] \leavevmode
boolean

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{\_generate\_phrase\_table() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer._generate_phrase_table}\pysiglinewithargsret{\bfcode{\_generate\_phrase\_table}}{\emph{phrase\_dict}}{}
generate the per line entry of a phrase table
\begin{description}
\item[{\textbf{parameters}, \textbf{types}::}] \leavevmode\begin{quote}\begin{description}
\item[{param phrase\_dict}] \leavevmode
a dictionary holding all suggestions, with the information of the modules that suggested it and the original token

\item[{type phrase\_dict}] \leavevmode
dictionary

\end{description}\end{quote}

\end{description}

iterate over the phrase\_dict and compile an etry of the followng format for each 
suggestion

ori \textbar{}\textbar{}\textbar{} sug \textbar{}\textbar{}\textbar{} 0 1 0 1 0 1 ....

the 0 and 1 indicate which module returned the suggestion. The order of the modules is 
given my the initialization of the modules.
The last 0 or 1 says if hunspell can find the suggestion as a word or not.

\end{fulllineitems}

\index{\_kill\_server\_mode() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer._kill_server_mode}\pysiglinewithargsret{\bfcode{\_kill\_server\_mode}}{\emph{proc}}{}
kill Moses server mode with the help of the process id.
\begin{description}
\item[{\textbf{parameters}, \textbf{types}::}] \leavevmode\begin{quote}\begin{description}
\item[{param proc}] \leavevmode
the process ideas collected when starting up server modes

\item[{type proc}] \leavevmode
list of integers

\end{description}\end{quote}

\end{description}

forces the kill of all running processes with the respective process id

\end{fulllineitems}

\index{\_normalize\_sentence() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer._normalize_sentence}\pysiglinewithargsret{\bfcode{\_normalize\_sentence}}{\emph{sentence}}{}
normalize the message, running all modueles and combining their output
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
preprocessed and flooding corrected text message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
return normalized sentences

\item[{rtype}] \leavevmode
list of strings

\end{description}\end{quote}

\end{description}

first all modules generate their suggestion, then these suggestions are collected
and written out to a phrase table, then the decision module generates one normalized            sentence

\end{fulllineitems}

\index{\_write\_phrase\_table() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer._write_phrase_table}\pysiglinewithargsret{\bfcode{\_write\_phrase\_table}}{\emph{phrase\_dict}, \emph{phrase\_dict\_location}}{}
write out the phrase table for the run of the decision module
\begin{description}
\item[{\textbf{parameters}, \textbf{types}::}] \leavevmode\begin{quote}\begin{description}
\item[{param phrase\_dict}] \leavevmode
a dictionary holding all suggestions, with the information of the modules that suggested it and the original token

\item[{type phrase\_dict}] \leavevmode
dictionary

\item[{param phrase\_dict\_location}] \leavevmode
the path to the phrase table

\item[{type phrase\_dict\_location}] \leavevmode
string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{initialize\_modules() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer.initialize_modules}\pysiglinewithargsret{\bfcode{initialize\_modules}}{}{}
initialize the different module objects

The module objects are initialized onces for every normalization run. The 
order of the initialization is important since this order is the same as the 
weights for the modules in the ini files.

For English there are 10 modules:

Word\_Split, Compound, Original, Abbreviation, SMT\_Token, SMT\_Unigram, SMT\_Bigram, SMT\_Cascaded, Transliterate, Hunspell

For Dutch there are 11 modules:

Word\_Split, Compound, Phonemic, Original, Abbreviation, SMT\_Token, SMT\_Unigram, SMT\_Bigram, SMT\_Cascaded, Transliterate, Hunspell

\end{fulllineitems}

\index{normalize\_text() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer.normalize_text}\pysiglinewithargsret{\bfcode{normalize\_text}}{\emph{t}}{}
returns the normalized sentences in a list

the preprocessed text is first flooding corrected
then the messages are sent into the pipeline and the normalized sentence is returned
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
object from class Text, containing the original and the preprocessed string

\item[{type t}] \leavevmode
Text object

\item[{return}] \leavevmode
return normalized sentences

\item[{rtype}] \leavevmode
list of strings

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{start\_server\_mode() (norm.normalizer.Normalizer method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.normalizer.Normalizer.start_server_mode}\pysiglinewithargsret{\bfcode{start\_server\_mode}}{}{}
start Moses server mode for all three SMT systems

the SMT modules use the Moses server mode which is started in the beginning of 
one run for each of the three modes: Token, Unigram and Bigram. They run on a random 
port between 30000 and 40000. The pids are stored and the server mode is stopped in case of
error or sucessful finish. Each Moses server waits for a certain amount of seconds after         start up to ensure it has enough time to run properly in the background.
The server modes use the .ini files which are located in ../static/Moses/decoder\_files. In              the ini files themselves you can see which phrase table or language model is accessed.

\end{fulllineitems}


\end{fulllineitems}



\section{Modules}
\label{API:modules}\label{API:module-norm.modules.abbreviation}\index{norm.modules.abbreviation (module)}\index{Abbreviation (class in norm.modules.abbreviation)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.abbreviation.Abbreviation}\pysiglinewithargsret{\strong{class }\code{norm.modules.abbreviation.}\bfcode{Abbreviation}}{\emph{normalizer}}{}
This module resolves the most frequent abbreviations
in social media content
\index{check\_hunspell() (norm.modules.abbreviation.Abbreviation method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.abbreviation.Abbreviation.check_hunspell}\pysiglinewithargsret{\bfcode{check\_hunspell}}{\emph{word}}{}
check word for spelling
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param word}] \leavevmode
a word

\item[{type word}] \leavevmode
unicode string

\item[{return}] \leavevmode
return True or False dependent on word being in dict or not

\item[{rtype}] \leavevmode
boolean

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{generate\_alternatives() (norm.modules.abbreviation.Abbreviation method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.abbreviation.Abbreviation.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

Looks up a token in an abbreviation lexicon and returns the long version in case the token is found.

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.compound}\index{norm.modules.compound (module)}\index{Compound (class in norm.modules.compound)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.compound.Compound}\pysiglinewithargsret{\strong{class }\code{norm.modules.compound.}\bfcode{Compound}}{\emph{normalizer}}{}
This class contains functions with which subsequent words can be checked for ``compoundness''.
If the spellchecker (hunspell) doesn't complain about the combination of subsequent words,
it is returned as an option.
\index{check\_hunspell() (norm.modules.compound.Compound method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.compound.Compound.check_hunspell}\pysiglinewithargsret{\bfcode{check\_hunspell}}{\emph{word}}{}
return hunspell result
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param word}] \leavevmode
a word

\item[{type word}] \leavevmode
unicode string

\item[{return}] \leavevmode
True or False dependent on whether a word is in hunspell dict or not

\item[{rtype}] \leavevmode
boolean

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{generate\_alternatives() (norm.modules.compound.Compound method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.compound.Compound.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

Compounds out of two subsequent tokens are built. Hunspell checks if the word is a correct word.

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.empty}\index{norm.modules.empty (module)}\index{Empty (class in norm.modules.empty)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.empty.Empty}\pysigline{\strong{class }\code{norm.modules.empty.}\bfcode{Empty}}
Assuming that words can be superfluous, this module returns an empty string.
\index{generate\_alternatives() (norm.modules.empty.Empty method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.empty.Empty.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.new_NE}\index{norm.modules.new\_NE (module)}\index{New\_NE (class in norm.modules.new\_NE)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE}\pysiglinewithargsret{\strong{class }\code{norm.modules.new\_NE.}\bfcode{New\_NE}}{\emph{normalizer}}{}
This module uses a crf model to predict whether a token is a 
named entity or not.

This modules in not included by default.
\index{\_replace\_atreplies() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE._replace_atreplies}\pysiglinewithargsret{\bfcode{\_replace\_atreplies}}{\emph{t}}{}
@replies are returned as a special character
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param t}] \leavevmode
token

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
t itself or  u''ਊ'' in case the token is an @-reply

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{\_run\_named\_entity\_replace() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE._run_named_entity_replace}\pysiglinewithargsret{\bfcode{\_run\_named\_entity\_replace}}{\emph{text\_string}}{}
Rule based component of the module. Search for upper case first letters, search in gazetteer list,
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param text\_string}] \leavevmode
flooding corrected original sentence

\item[{type t}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}u''ਊ''{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{clean\_up() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE.clean_up}\pysiglinewithargsret{\bfcode{clean\_up}}{}{}
Delete the directory with all texsis files.

\end{fulllineitems}

\index{generate\_alternatives() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Run a crf classifier to find out if a token is a NE or not.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the ਊ token to hand over the information that a token is an NE of the form {[}{[}ori,{[}ori{]}{]},  {[}ori2,  {[}u'ਊ'{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

The information if a token is an NE or not is not included directly but can be used as a feature in the phrase table.

\end{fulllineitems}

\index{get\_labels() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE.get_labels}\pysiglinewithargsret{\bfcode{get\_labels}}{\emph{sentence}}{}
For each word in the input sentence the lable (NE or not) is extracted from the file predicted by crf.
If the label is 1 a special character is returned as a suggestion, if not the original token is returned.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}u''ਊ''{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{make\_feature\_file() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE.make_feature_file}\pysiglinewithargsret{\bfcode{make\_feature\_file}}{}{}
An external python script (language specific) is called to compile the feature files used for NE prediction.
The script expects the following input:
\begin{itemize}
\item {} 
language

\item {} 
texsis POS file

\item {} 
texsis tok file

\item {} 
gazetteer file

\item {} 
celex file

\item {} 
output file

\end{itemize}

All these files can be found in the static directory.

\end{fulllineitems}

\index{run\_texsis() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE.run_texsis}\pysiglinewithargsret{\bfcode{run\_texsis}}{}{}
Texsis is used to pos tag the sentence. This information is used as a feature in the crf classification.

\end{fulllineitems}

\index{write\_file() (norm.modules.new\_NE.New\_NE method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.new_NE.New_NE.write_file}\pysiglinewithargsret{\bfcode{write\_file}}{\emph{sent}}{}
The sentence is written to a file (one word per line) and stored in a directory. Texsis can be run on this directory to 
generate pos tags for each word in the sentence.
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.original}\index{norm.modules.original (module)}\index{Original (class in norm.modules.original)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.original.Original}\pysigline{\strong{class }\code{norm.modules.original.}\bfcode{Original}}
This class contains functions which return the original
as an option
\index{generate\_alternatives() (norm.modules.original.Original method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.original.Original.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.phonemic}\index{norm.modules.phonemic (module)}\index{Phonemic (class in norm.modules.phonemic)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.phonemic.Phonemic}\pysigline{\strong{class }\code{norm.modules.phonemic.}\bfcode{Phonemic}}
Access via web service the MBT grapeme-to-phoneme-to-grapheme conversion.
Implemented by Guy DePauw.
\index{generate\_alternatives() (norm.modules.phonemic.Phonemic method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.phonemic.Phonemic.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.smt}\index{norm.modules.smt (module)}\index{SMT\_Token (class in norm.modules.smt)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Token}\pysiglinewithargsret{\strong{class }\code{norm.modules.smt.}\bfcode{SMT\_Token}}{\emph{normalizer}}{}
This class contains functions with which the SMT on the token level can be performed.
\index{generate\_alternatives() (norm.modules.smt.SMT\_Token method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Token.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{SMT\_Cascaded (class in norm.modules.smt)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Cascaded}\pysiglinewithargsret{\strong{class }\code{norm.modules.smt.}\bfcode{SMT\_Cascaded}}{\emph{normalizer}}{}
This class contains functions with which the SMT on first the token 
and subsequently on the unigram level can be performed.
\index{generate\_alternatives() (norm.modules.smt.SMT\_Cascaded method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Cascaded.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{SMT\_Unigram (class in norm.modules.smt)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Unigram}\pysiglinewithargsret{\strong{class }\code{norm.modules.smt.}\bfcode{SMT\_Unigram}}{\emph{normalizer}}{}
This class contains functions with which the SMT on the unigram level can be performed.
\index{generate\_alternatives() (norm.modules.smt.SMT\_Unigram method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Unigram.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\index{SMT\_Bigram (class in norm.modules.smt)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Bigram}\pysiglinewithargsret{\strong{class }\code{norm.modules.smt.}\bfcode{SMT\_Bigram}}{\emph{normalizer}}{}
This class contains functions with which the SMT on the bigram level can be performed.
\index{generate\_alternatives() (norm.modules.smt.SMT\_Bigram method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.smt.SMT_Bigram.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.spellcheck}\index{norm.modules.spellcheck (module)}\index{Hunspell (class in norm.modules.spellcheck)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.spellcheck.Hunspell}\pysiglinewithargsret{\strong{class }\code{norm.modules.spellcheck.}\bfcode{Hunspell}}{\emph{normalizer}}{}
This class contains functions that check a word with the hunspell spell checker.
In case it is recognized as incorrectly spelled, alternative spelling options are suggested
\index{find\_suggestions() (norm.modules.spellcheck.Hunspell method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.spellcheck.Hunspell.find_suggestions}\pysiglinewithargsret{\bfcode{find\_suggestions}}{\emph{word}}{}
use the hunspell spell checker for correct suggestions. take the first suggestion (levenshtein distance smallest).
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param word}] \leavevmode
a token

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
hunspell corrected suggestion

\item[{rtype}] \leavevmode
unicode string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{generate\_alternatives() (norm.modules.spellcheck.Hunspell method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.spellcheck.Hunspell.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}

\phantomsection\label{API:module-norm.modules.wordsplit}\index{norm.modules.wordsplit (module)}\index{Word\_Split (class in norm.modules.wordsplit)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.wordsplit.Word_Split}\pysiglinewithargsret{\strong{class }\code{norm.modules.wordsplit.}\bfcode{Word\_Split}}{\emph{normalizer}}{}
This class contains functions with which subsequent words can be checked for ``compoundness''.
It uses word frequencies from the cgn corpus to decide if a word should be split or not.
It makes use of the decompounder perl script that comes together with Moses.
\index{generate\_alternatives() (norm.modules.wordsplit.Word\_Split method)}

\begin{fulllineitems}
\phantomsection\label{API:norm.modules.wordsplit.Word_Split.generate_alternatives}\pysiglinewithargsret{\bfcode{generate\_alternatives}}{\emph{sentence}}{}
Generate suggestion
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param sentence}] \leavevmode
flooding corrected original message

\item[{type sentence}] \leavevmode
unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}


\end{fulllineitems}



\section{Util}
\label{API:util}\label{API:module-norm.util}\index{norm.util (module)}\index{align() (in module norm.util)}

\begin{fulllineitems}
\phantomsection\label{API:norm.util.align}\pysiglinewithargsret{\code{norm.util.}\bfcode{align}}{\emph{ori}, \emph{tgt}}{}
align two sentences using the python sequence aligner
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param ori}] \leavevmode
an original sentence

\item[{type ori}] \leavevmode
Unicode string

\item[{param tgt}] \leavevmode
a reference sentence

\item[{type tgt}] \leavevmode
Unicode string

\item[{return}] \leavevmode
original tokens aligned with the suggestion of the form {[}{[}ori,{[}sug{]}{]},{[}ori2,{[}sug2{]}{]}{]}

\item[{rtype}] \leavevmode
list of lists

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{calculate\_cer() (in module norm.util)}

\begin{fulllineitems}
\phantomsection\label{API:norm.util.calculate_cer}\pysiglinewithargsret{\code{norm.util.}\bfcode{calculate\_cer}}{\emph{ref}, \emph{hyp}}{}
calculate CER with the help of dynamic programming alignment
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param ref}] \leavevmode
a reference sentence

\item[{type ref}] \leavevmode
Unicode string

\item[{param hyp}] \leavevmode
a hypothesis sentence

\item[{type hyp}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the CER between ref and hyp

\item[{rtype}] \leavevmode
float

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{calculate\_wer() (in module norm.util)}

\begin{fulllineitems}
\phantomsection\label{API:norm.util.calculate_wer}\pysiglinewithargsret{\code{norm.util.}\bfcode{calculate\_wer}}{\emph{r}, \emph{h}}{}
calculate WER with the help of dynamic programming alignment
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param ref}] \leavevmode
a reference sentence

\item[{type ref}] \leavevmode
Unicode string

\item[{param hyp}] \leavevmode
a hypothesis sentence

\item[{type hyp}] \leavevmode
Unicode string

\item[{return}] \leavevmode
the WER between ref and hyp

\item[{rtype}] \leavevmode
float

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{get\_random\_phrase\_table\_path() (in module norm.util)}

\begin{fulllineitems}
\phantomsection\label{API:norm.util.get_random_phrase_table_path}\pysiglinewithargsret{\code{norm.util.}\bfcode{get\_random\_phrase\_table\_path}}{\emph{prefix='phrase\_table'}}{}
get a random phrase table name with a prefix and a 6 character long capital-letter-digits-string

file will be located in ../log/phrasetables
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param prefix}] \leavevmode
optional: prefix for the temporary file, default = phrase\_table

\item[{type prefix}] \leavevmode
Unicode string

\item[{return}] \leavevmode
path to the temporary file

\item[{rtype}] \leavevmode
string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{get\_random\_tmp\_eval\_path() (in module norm.util)}

\begin{fulllineitems}
\phantomsection\label{API:norm.util.get_random_tmp_eval_path}\pysiglinewithargsret{\code{norm.util.}\bfcode{get\_random\_tmp\_eval\_path}}{\emph{prefix='phrase\_table'}}{}
get a random evaluation directory name with a prefix and a 6 character long capital-letter-digits-string

file will be located in /tmp/eval\_options/
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param prefix}] \leavevmode
optional: prefix for the temporary file, default = phrase\_table

\item[{type prefix}] \leavevmode
Unicode string

\item[{return}] \leavevmode
path to the temporary file

\item[{rtype}] \leavevmode
string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}

\index{get\_random\_tmp\_path() (in module norm.util)}

\begin{fulllineitems}
\phantomsection\label{API:norm.util.get_random_tmp_path}\pysiglinewithargsret{\code{norm.util.}\bfcode{get\_random\_tmp\_path}}{\emph{prefix='norm'}}{}
get a random path consisting of the prefix name and a 6 character long capital-letter-digits-string

file will be located in /tmp
\begin{description}
\item[{\textbf{parameters}, \textbf{types},**return**,**return types**::}] \leavevmode\begin{quote}\begin{description}
\item[{param prefix}] \leavevmode
optional: prefix for the temporary file, default = norm

\item[{type prefix}] \leavevmode
Unicode string

\item[{return}] \leavevmode
path to the temporary file

\item[{rtype}] \leavevmode
string

\end{description}\end{quote}

\end{description}

\end{fulllineitems}



\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\emph{genindex}

\item {} 
\emph{modindex}

\item {} 
\emph{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{n}
\item {\texttt{norm.data}}, \pageref{API:module-norm.data}
\item {\texttt{norm.modules.abbreviation}}, \pageref{API:module-norm.modules.abbreviation}
\item {\texttt{norm.modules.compound}}, \pageref{API:module-norm.modules.compound}
\item {\texttt{norm.modules.empty}}, \pageref{API:module-norm.modules.empty}
\item {\texttt{norm.modules.flooding}}, \pageref{API:module-norm.modules.flooding}
\item {\texttt{norm.modules.new\_NE}}, \pageref{API:module-norm.modules.new_NE}
\item {\texttt{norm.modules.original}}, \pageref{API:module-norm.modules.original}
\item {\texttt{norm.modules.phonemic}}, \pageref{API:module-norm.modules.phonemic}
\item {\texttt{norm.modules.smt}}, \pageref{API:module-norm.modules.smt}
\item {\texttt{norm.modules.spellcheck}}, \pageref{API:module-norm.modules.spellcheck}
\item {\texttt{norm.modules.wordsplit}}, \pageref{API:module-norm.modules.wordsplit}
\item {\texttt{norm.normalizer}}, \pageref{API:module-norm.normalizer}
\item {\texttt{norm.prepro.rewrite}}, \pageref{API:module-norm.prepro.rewrite}
\item {\texttt{norm.util}}, \pageref{API:module-norm.util}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
